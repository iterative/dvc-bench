name: build
on:
  pull_request: {}
  push:
    branches:
      - master
  schedule:
    - cron: '0 0 * * *'

env:
  DVC_TEST: "true"

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v2
        with:
            python-version: 3.7
      - name: install requirements
        run: pip install -r requirements.txt
      - name: check project styling
        run: pre-commit run --all-files
  gen:
    runs-on: ubuntu-latest
    outputs:
      tests: ${{ steps.tests.outputs.tests }}
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v2
        with:
            python-version: 3.7
      - run: pip install asv virtualenv
      - name: generate results/benchmarks.json
        run: |
          asv machine --yes
          asv update
          ls -la results/
      - id: tests
        run: echo "::set-output name=tests::$(jq -c 'keys' results/benchmarks.json | jq -c 'del(.[] | select(. == "version"))')"
  build:
    needs: [gen]
    timeout-minutes: 4320
    name: run ${{ matrix.test }}
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
#        os: [windows-2019, macos-10.15, ubuntu-18.04]
        os: [ubuntu-18.04]
        test: ${{fromJson(needs.gen.outputs.tests)}}
    steps:
      - uses: actions/setup-python@v2
        with:
            python-version: 3.7
      - uses: actions/checkout@v2
      - name: install requirements
        run: pip install -r requirements.txt
      - name: run tests
        run: python -m py.test
      - name: setup asv
        run: python write_asv_machine.py
      - name: configure aws credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-2
      - name: configure gcloud credentials
        uses: google-github-actions/setup-gcloud@master
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
          service_account_key: ${{ secrets.GCP_SA_KEY }}
          export_default_credentials: true
      - name: download data
        uses: nick-invision/retry@v2
        with:
          timeout_minutes: 30
          max_attempts: 5
          command: dvc pull data/cats_dogs.dvc
      - name: download existing results
        run: aws s3 cp --recursive s3://dvc-bench/latest_results results
      - name: convert revs
        run: asv check && python revs_to_sha.py
      - name: run benchmarks
        shell: bash
        env:
          DVC_BENCH_AZURE_CONN_STR: ${{ secrets.DVC_BENCH_AZURE_CONN_STR }}
          DVC_BENCH_ASV_ARGS: "${{ github.event_name == 'push' && 'HASHFILE:hashes.txt' || '' }}"
#          DVC_BENCH_CONFIG: ${{ env.GITHUB_WORKSPACE }}/all.json
        run: ./run.sh $DVC_BENCH_ASV_ARGS --bench ${{ matrix.test }}
      - name: upload raw results
        uses: actions/upload-artifact@v2
        with:
          name: results-aws-runner
          path: results
  publish:
    name: join results and publish
    needs: build
    if: github.event_name != 'pull_request'
    runs-on: ubuntu-18.04
    steps:
      - uses: actions/setup-python@v2
        with:
          python-version: 3.7
      - uses: actions/checkout@v2
      - name: install requirements
        run: pip install -r requirements.txt
      - name: download ubuntu results
        uses: actions/download-artifact@v2
        with:
          name: results-aws-runner
          path: /tmp/results-ubuntu
      - name: configure aws credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-2
      - name: download existing results
        run: aws s3 cp --recursive s3://dvc-bench/latest_results results
      - name: join results
        shell: bash
        run: |
          cp -r /tmp/results-ubuntu/linux* results/
          if [[ "$GITHUB_EVENT_NAME" == "schedule" ]]; then cp /tmp/results-ubuntu/benchmarks.json results/benchmarks.json; fi
      - name: create static html
        run: asv update && asv publish
      - name: upload new results
        run: aws s3 cp --recursive results s3://dvc-bench/latest_results
      - name: deploy new benchmarks to github pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: html
