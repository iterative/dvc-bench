name: build
on:
  pull_request: {}
  push:
    branches:
      - main
  schedule:
    - cron: '0 0 * * *'

  workflow_dispatch:
    inputs:
      dataset:
        description: "Dataset Size"
        required: false
        default: "small"
        type: choice
        options:
          - tiny
          - small
          - large
          - mnist

env:
  DVC_TEST: "true"
  FORCE_COLOR: "1"
  DATASET: ${{ github.event.inputs.dataset || ( github.event_name == 'schedule' && 'mnist' || 'small' ) }}

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v4
        with:
            python-version: "3.10"
      - name: install requirements
        run: |
          pip install -U pip
          pip install wheel
          pip install -r requirements.txt
      - name: check project styling
        run: pre-commit run --all-files --show-diff-on-failure
  gen:
    runs-on: ubuntu-latest
    outputs:
      tests: ${{ steps.tests.outputs.tests }}
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v4
        with:
            python-version: "3.10"
      - name: install reqs
        run: pip install -r requirements.txt
      - id: tests
        run: echo "::set-output name=tests::$(./scripts/ci/list_tests.sh)"
  build:
    needs: [gen]
    timeout-minutes: 120
    name: run ${{ matrix.test.name }}
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
#        os: [windows-2019, macos-10.15, ubuntu-latest]
        os: [ubuntu-latest]
        test: ${{fromJson(needs.gen.outputs.tests)}}
    steps:
      - uses: actions/setup-python@v4
        with:
            python-version: "3.10"
      - uses: actions/checkout@v2
      - name: install requirements
        run: |
            pip install -r requirements.txt
            pip install git+https://github.com/iterative/dvc
      - name: run benchmarks
        shell: bash
        env:
          DVC_BENCH_AZURE_CONN_STR: ${{ secrets.DVC_BENCH_AZURE_CONN_STR }}
        run: pytest --benchmark-save ${{ matrix.test.name }} --benchmark-group-by func --dvc-revs main,2.24.0,2.18.1,2.11.0,2.6.3 ${{ matrix.test.path }} --size ${DATASET}
      - name: upload raw results
        uses: actions/upload-artifact@v3
        with:
          name: .benchmarks
          path: .benchmarks
  publish:
    name: join results and publish
    needs: build
    runs-on: ubuntu-latest
    steps:
      - uses: actions/setup-python@v4
        with:
          python-version: "3.10"
      - uses: actions/checkout@v2
      - name: install requirements
        run: pip install -r requirements.txt
      - name: download ubuntu results
        uses: actions/download-artifact@v3
      - name: compare results
        shell: bash
        run: ./scripts/ci/gen_html.sh
      - name: create md
        if: github.event_name == 'pull_request'
        id: get-comment-body
        run: |
          cat raw
          body="\`\`\`\n$(cat raw | sed -r "s/\x1B\[([0-9]{1,3}(;[0-9]{1,2})?)?[mGK]//g")\n\`\`\`"
          body="${body//'%'/'%25'}"
          body="${body//$'\n'/'%0A'}"
          body="${body//$'\r'/'%0D'}"
          echo ::set-output name=body::$body
      - name: post comment
        if: ${{ github.event_name == 'pull_request' && ! github.event.pull_request.head.repo.fork }}
        uses: peter-evans/create-or-update-comment@v2
        with:
          issue-number: ${{ github.event.pull_request.number }}
          body: ${{ steps.get-comment-body.outputs.body }}
      - name: deploy new benchmarks to github pages
        if: ${{ github.event_name == 'schedule' }}
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: html
