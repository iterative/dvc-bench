name: 'DVC Benchmarks'
description: 'Run dvc benchmarks'
inputs:
  pytest_options:
    description: 'pytest options'
    default: ""
    required: false
runs:
  using: "composite"
  steps:
    - name: clone dvc-bench
      uses: actions/checkout@v2
      with:
        path: dvc-bench
        repository: iterative/dvc-bench
    - name: install dvc-bench requirements
      working-directory: dvc-bench
      shell: bash
      run: pip install -r requirements.txt
    - name: checkout base dvc version
      uses: actions/checkout@v2
      with:
        path: dvc-bench/dvc
        ref: ${{ github.event.pull_request.base.sha }}
    - name: install base dvc version
      shell: bash
      working-directory: dvc-bench/dvc
      run: pip install '.[all,tests]'
    - name: run benchmarks for base version
      shell: bash
      working-directory: dvc-bench
      env:
        DVC_TEST: "true"
      run: |
        dvc --version
        pytest --benchmark-autosave ${{ inputs.pytest_options }} tests/benchmarks
    - name: checkout PR dvc version
      uses: actions/checkout@v2
      with:
        path: dvc-bench/dvc
        fetch-depth: 0
    - name: install PR dvc version
      shell: bash
      working-directory: dvc-bench/dvc
      run: pip install '.[all,tests]'
    - name: run benchmarks for PR
      shell: bash
      working-directory: dvc-bench
      env:
        DVC_TEST: "true"
      run: |
        dvc --version
        PY_COLORS=1 pytest --benchmark-compare --benchmark-compare-fail=median:5% --benchmark-group-by name ${{ inputs.pytest_options}} tests/benchmarks
